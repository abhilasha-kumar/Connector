{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_594629nfMU"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AbdIoQI7noEY"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psutil'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ce0568ae8a1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpsutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'psutil'"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import json\n",
    "import itertools\n",
    "import psutil\n",
    "import sys\n",
    "import scipy.spatial.distance\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "from functools import lru_cache\n",
    "from numpy.random import randint\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from numpy.linalg import matrix_power\n",
    "from scipy.special import expit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZiFWu8fuYpXx"
   },
   "outputs": [],
   "source": [
    "def read_vecs(path_to_df):\n",
    "    # after reading in, we drop first row & column (these are indices, not vectors)\n",
    "    vecs_pd = pd.read_csv(path_to_df, sep=',',header=None)\n",
    "    vecs_pd_new = vecs_pd.iloc[1:]\n",
    "    vecs_pd_new = vecs_pd_new.drop([vecs_pd_new.columns[0]], axis = 1)\n",
    "    return vecs_pd_new.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkXo_Ysanp92"
   },
   "source": [
    "# Import large dataframe giving the full vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 182,
     "status": "ok",
     "timestamp": 1626742006345,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "U3iBYEMWnpcY",
    "outputId": "b20683f3-da39-46ec-f134-6a2efb10aae9"
   },
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"../data/connector_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2MFRtHgnwIN"
   },
   "source": [
    "# Read in Pretrained Semantic Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 12218 words, we have (1) glove, (2) SWOW, and (3) non-contextual BERT embeddings.\n",
    "\n",
    "SWOW has 2 versions : PPMI and Random Walk. We use RW.\n",
    "\n",
    "The BERT context-free embeddings obtained by \"CLS [word] SEP\": summed across last four layers (768-dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YZqmDQr-nxik"
   },
   "outputs": [],
   "source": [
    "representations = {}\n",
    "representations['glove'] = read_vecs(\"../data/swow12217_glove2017wiki_vectors.csv\")\n",
    "representations['swow'] = np.array(pd.read_csv(\"../data/SWOW_R123_rw_k300.csv\", header=None))\n",
    "representations['bert-sum'] = read_vecs(\"../data/bert_contextfree_sum.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4qERX9poGEj"
   },
   "source": [
    "# Read in the game boards used in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j3EntMS7oHJd"
   },
   "outputs": [],
   "source": [
    "with open('../data/boards.json', 'r') as json_file:\n",
    "    boards = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uHvyQXJoSns"
   },
   "source": [
    "# Read in the clues produced in the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1620785903824,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "N2HX_JTdoUA7",
    "outputId": "33a4e1f1-6b8a-405d-9cb5-991f0caf0c73"
   },
   "outputs": [],
   "source": [
    "## load cleaned up data from experiment\n",
    "expdata = pd.read_csv(\"../data/final_board_clues_all.csv\", encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBiSuy_poVpI"
   },
   "source": [
    "# RSA functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6VJDvQAdoQA"
   },
   "source": [
    "### Extract wordpairs\n",
    "For each board, we need to get all of the possible pairs of words on the board in an easy-to-work-with format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JjlD7j9oo8sH"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Board</th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>wordpair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>angry</td>\n",
       "      <td>adore</td>\n",
       "      <td>angry-adore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>angry</td>\n",
       "      <td>burglar</td>\n",
       "      <td>angry-burglar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>angry</td>\n",
       "      <td>rumor</td>\n",
       "      <td>angry-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>angry</td>\n",
       "      <td>depth</td>\n",
       "      <td>angry-depth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>angry</td>\n",
       "      <td>anchor</td>\n",
       "      <td>angry-anchor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Board  Word1    Word2       wordpair\n",
       "0  e1_board1_words  angry    adore    angry-adore\n",
       "1  e1_board1_words  angry  burglar  angry-burglar\n",
       "2  e1_board1_words  angry    rumor    angry-rumor\n",
       "3  e1_board1_words  angry    depth    angry-depth\n",
       "4  e1_board1_words  angry   anchor   angry-anchor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## these combos need to be created at the board level\n",
    "def compute_board_combos(board_name):\n",
    "    board = boards[board_name]\n",
    "    all_possible_combs = list(itertools.combinations(board, 2))\n",
    "    combs_df = pd.DataFrame(all_possible_combs, columns =['Word1', 'Word2'])\n",
    "    combs_df[\"wordpair\"] = combs_df[\"Word1\"] + '-'+ combs_df[\"Word2\"]\n",
    "    return combs_df\n",
    "\n",
    "allcombinations_df = pd.DataFrame(columns=['Board', 'Word1','Word2', 'wordpair'])\n",
    "board_combos = {board_name : compute_board_combos(board_name) for board_name in boards.keys()}\n",
    "for board in board_combos:\n",
    "    newdf = board_combos[board]\n",
    "    newdf.insert(loc=0, column='Board', value=board)\n",
    "    allcombinations_df = pd.concat([allcombinations_df, newdf])\n",
    "\n",
    "allcombinations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAGGI8X4cHcR"
   },
   "source": [
    "now that we have the combos, we can make a little helper function to get the wordpair lists for a given board as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1620787533863,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "uHrJuIJNAOud",
    "outputId": "327a8731-ef50-46c1-9e13-5b2e51d9fa3c"
   },
   "outputs": [],
   "source": [
    "def get_wordpair_list(board_name) :\n",
    "  return list(board_combos[board_name]['wordpair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BsZEuT1ddtCz"
   },
   "source": [
    "### get matrix of similarities\n",
    "this serves as our literal semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "P7uR4l5gAQ4e"
   },
   "outputs": [],
   "source": [
    "## we need to create a exp(clue-w1 * clue-cw2) matrix of size Nx190 for each board\n",
    "## where N is the size of the search space\n",
    "## this is normalized by-row for literal guesser\n",
    "## normalized by column for pragmatic speaker\n",
    "## and then normalized by row again for pragmetic guesser\n",
    "def create_board_matrix(combs_df, context_board, embeddings):\n",
    "    # grab subset of words in given board and their corresponding glove vectors\n",
    "    board_df = sample_df[sample_df['Word'].isin(context_board)]\n",
    "    board_word_indices = list(board_df.index)\n",
    "    board_words = board_df[\"Word\"]\n",
    "    board_vectors = embeddings[board_word_indices]\n",
    "\n",
    "    ## clue_sims is the similarity of ALL clues in full searchspace (size N) to EACH word on board (size 20)\n",
    "    clue_sims = 1 - scipy.spatial.distance.cdist(board_vectors, embeddings, 'cosine')\n",
    "\n",
    "    ## once we have the similarities of the clue to the words on the board\n",
    "    ## we define a multiplicative function that maximizes these similarities\n",
    "    board_df.reset_index(inplace = True)\n",
    "\n",
    "    ## next we find the product of similarities between c-w1 and c-w2 for that specific board's 190 word-pairs\n",
    "    ## this gives us a 190 x N array of product similarities for a given combs_df\n",
    "    ## specifically, for each possible pair, pull out \n",
    "    f_w1_list =  np.array([clue_sims[board_df[board_df[\"Word\"]==row[\"Word1\"]].index.values[0]]\n",
    "                         for  index, row in combs_df.iterrows()])\n",
    "    f_w2_list =  np.array([clue_sims[board_df[board_df[\"Word\"]==row[\"Word2\"]].index.values[0]] \n",
    "                         for  index, row in combs_df.iterrows()])\n",
    "\n",
    "    # result is of length 190 for the product of similarities (i.e. how similar each word i is to BOTH in pair)\n",
    "    return ((f_w1_list + 1) /2) * ((f_w2_list + 1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Q-6S5SOBA3Gn"
   },
   "outputs": [],
   "source": [
    "board_matrices = {\n",
    "    key : {board_name : create_board_matrix(board_combos[board_name], boards[board_name], embedding) \n",
    "           for board_name in boards.keys()}\n",
    "    for (key, embedding) in representations.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTFBYseDdy2E"
   },
   "source": [
    "### Literal Guesser NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given a 190xN matrix of clue-w1 * clue-w2 products, the literal guesser computes softmax over pairs for each possible clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "skjCu_CJK85n"
   },
   "outputs": [],
   "source": [
    "def literal_guesser_np(board_name, representation):\n",
    "    boardmatrix = board_matrices[representation][board_name]\n",
    "    return softmax(boardmatrix, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnCh3E62d1TN"
   },
   "source": [
    "### Pragmatic Speaker NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given a Nx190 matrix of clue products, pragmatic speaker first computes literal guesser softmax for each clue in searchspace, then computes softmax over all clues for a specific word-pair. this yields a Nx190 array with literal guesser softmax values for each possible clue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to implement S1 = beta * (ln(G0)- cost).\n",
    "\n",
    "we use frequency-based cost (higher frequency means lower cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6LELBQn2DIFT"
   },
   "outputs": [],
   "source": [
    "def pragmatic_speaker_np(board_name, beta, costweight, representation):\n",
    "    literal_guesser_prob = np.log(literal_guesser_np(board_name, representation))\n",
    "    clues_cost = -np.array(list(sample_df[\"LgSUBTLWF\"]))\n",
    "    utility = (1-costweight) * literal_guesser_prob - costweight * clues_cost\n",
    "    return softmax(beta * utility, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZieYkjDMd3ws"
   },
   "source": [
    "### Pragmatic Guesser NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a 190xN matrix of clue products, pragmatic guesser computes pragamtic speaker softmax for EACH wordpair given a particular clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wrz24elMGEiK"
   },
   "outputs": [],
   "source": [
    "def pragmatic_guesser_np(board_name, beta, costweight, representation):\n",
    "    return softmax(np.log(pragmatic_speaker_np(board_name, beta, costweight, representation)), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7chhjmljeRzj"
   },
   "source": [
    "### Test models on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 859,
     "status": "ok",
     "timestamp": 1620782275269,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "5LqRAmn4bHv1",
    "outputId": "fadcb5c2-7fd9-4d93-a3e1-948c0de148b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "literal guesser prediction is: algebra-better\n",
      "top10 prag speaker predictions are: ['algebra', 'exam', 'mathematics', 'exams', 'calculus']\n",
      "pragmatic guesser prediction is: depth-algebra\n"
     ]
    }
   ],
   "source": [
    "clue = 'equation'\n",
    "target = 'exam-algebra'\n",
    "wordpairlist = get_wordpair_list('e1_board1_words')\n",
    "target_index = wordpairlist.index(target)\n",
    "clue_index = list(sample_df[\"Word\"]).index(clue)\n",
    "\n",
    "a = literal_guesser_np('e1_board1_words', 'glove')[:,clue_index]\n",
    "y = pragmatic_speaker_np('e1_board1_words', 18.858, 0.004, 'glove')\n",
    "top10 = y[target_index,:].argsort()[-5:][::-1].tolist()\n",
    "top10_words = [list(sample_df[\"Word\"])[x] for x in top10]\n",
    "z = pragmatic_guesser_np('e1_board1_words', 18.858, 0.004, 'glove')[:,clue_index]\n",
    "\n",
    "print(\"literal guesser prediction is:\", wordpairlist[np.argmax(a)])\n",
    "print(\"top10 prag speaker predictions are:\", top10_words)\n",
    "print(\"pragmatic guesser prediction is:\", wordpairlist[np.argmax(z)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBbehImBsZVn"
   },
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1620785211948,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "ApJNxZzktNIE",
    "outputId": "cd767e1c-eb5b-4b93-d596-9a885674df39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Board</th>\n",
       "      <th>boardwords</th>\n",
       "      <th>boardnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>[angry, adore, burglar, rumor, depth, anchor, ...</td>\n",
       "      <td>e1_board1_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList2</td>\n",
       "      <td>[alto, faith, beginning, brake, birds, aircraf...</td>\n",
       "      <td>e1_board2_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList3</td>\n",
       "      <td>[circle, dance, day, dark, famine, calorie, hu...</td>\n",
       "      <td>e1_board3_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList4</td>\n",
       "      <td>[ceiling, carpet, corpse, fight, extension, fa...</td>\n",
       "      <td>e1_board4_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList5</td>\n",
       "      <td>[ancestor, child, carriage, done, denial, disr...</td>\n",
       "      <td>e1_board5_words</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experiment       Board                                         boardwords  \\\n",
       "0         E1  TrialList1  [angry, adore, burglar, rumor, depth, anchor, ...   \n",
       "1         E1  TrialList2  [alto, faith, beginning, brake, birds, aircraf...   \n",
       "2         E1  TrialList3  [circle, dance, day, dark, famine, calorie, hu...   \n",
       "3         E1  TrialList4  [ceiling, carpet, corpse, fight, extension, fa...   \n",
       "4         E1  TrialList5  [ancestor, child, carriage, done, denial, disr...   \n",
       "\n",
       "        boardnames  \n",
       "0  e1_board1_words  \n",
       "1  e1_board2_words  \n",
       "2  e1_board3_words  \n",
       "3  e1_board4_words  \n",
       "4  e1_board5_words  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create boards and merge with expdata\n",
    "combined_boards_df = pd.DataFrame(columns=['Experiment', 'Board','boardwords'])\n",
    "combined_boards_df[\"Experiment\"]  = [\"E1\"] * 10 + [\"E2\"] * 10\n",
    "combined_boards_df[\"Board\"] = [\"TrialList\" + str(i) for i in range(1,11)] * 2\n",
    "combined_boards_df[\"boardnames\"] = (['e1_board' + str(i) + '_words' for i in range(1,11)] \n",
    "                                  + ['e2_board' + str(i) + '_words' for i in range(1,11)])\n",
    "combined_boards_df[\"boardwords\"] = [boards[n] for n in combined_boards_df[\"boardnames\"]]\n",
    "combined_boards_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1620785461063,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "k0ax0K8mVL04",
    "outputId": "e98f4d92-6f0a-4a1b-92db-2e9f382534f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>boardnames</th>\n",
       "      <th>wordpair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>void</td>\n",
       "      <td>couch</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>void-couch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giggle</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>giggle-abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>exam-algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tea</td>\n",
       "      <td>bean</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board10_words</td>\n",
       "      <td>tea-bean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tourist</td>\n",
       "      <td>comedy</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board10_words</td>\n",
       "      <td>tourist-comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word1     Word2 Experiment        boardnames         wordpair\n",
       "0     void     couch         E1   e1_board1_words       void-couch\n",
       "1   giggle  abnormal         E1   e1_board1_words  giggle-abnormal\n",
       "2     exam   algebra         E1   e1_board1_words     exam-algebra\n",
       "3      tea      bean         E1  e1_board10_words         tea-bean\n",
       "4  tourist    comedy         E1  e1_board10_words   tourist-comedy"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## need to get similarity matrix of these words in this order to work with\n",
    "target_df = pd.read_csv(\"../data/connector_wordpairs_boards.csv\")\n",
    "target_df[\"wordpair\"]= target_df[\"Word1\"]+ \"-\"+target_df[\"Word2\"]\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MoszZoUXKTU"
   },
   "source": [
    "## Speaker predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the best-fitting params for each model (see Optimizing parameters section below for code used to find these values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7o81fCYkj6Yl"
   },
   "outputs": [],
   "source": [
    "rsa_optimal_params = {\n",
    "    'swow' : (25.1522030761838, 0.03863169001849234),\n",
    "    'glove' : (22.336514544537227, 0.039),\n",
    "    'bert-sum' : (29.709602301411962, 0.031659060110267576), #-17533\n",
    "}\n",
    "\n",
    "board_optimal_params = {\n",
    "    'swow' : (23.488850322875496, 1), # -13204\n",
    "    'glove' : (20.952928531665275, 1), # -15774.814774380024)\n",
    "    'bert-sum' : (19.983835225540847, 0.787924454045298),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute scores\n",
    "Our main DV is to likelihood of the data, so we compute scores & ranks for all possible clues produced by the participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speaker_scores(group, speaker_word_pairs, y, y_sorted) :\n",
    "    speaker_prob = []\n",
    "    speaker_rank = []\n",
    "    for index, row in group.iterrows():\n",
    "        clue1 = row[\"Clue1\"]\n",
    "        wordpair = str(row[\"wordpair\"]).replace(\" \", \"\")\n",
    "        wordpair_index = speaker_word_pairs.index(wordpair)\n",
    "        w1_index, w2_index = [list(sample_df[\"Word\"]).index(word) for word in wordpair.split('-')]\n",
    "        \n",
    "        # find index of clue\n",
    "        if clue1 in list(sample_df[\"Word\"]):\n",
    "            clue_index = list(sample_df[\"Word\"]).index(clue1)\n",
    "            clue_probs = y[wordpair_index, clue_index]\n",
    "            clue_rank = np.nonzero(y_sorted==clue_index)[1][wordpair_index]\n",
    "        else:\n",
    "            clue_rank = \"NA\"\n",
    "            clue_probs = \"NA\"\n",
    "\n",
    "        speaker_prob.append(clue_probs)\n",
    "        speaker_rank.append(clue_rank)\n",
    "    return speaker_prob, speaker_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42011,
     "status": "ok",
     "timestamp": 1620796384376,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "diTU6Zk20fZf",
    "outputId": "a50381e4-2a34-448c-87f2-23145c0ab88e"
   },
   "outputs": [],
   "source": [
    "speakerprobs_df = pd.DataFrame(columns=['representation', 'Experiment','Board', \"Word1\", \"Word2\", \"Clue1\", \"clueCount\", \"wordpair\", \"prag_speaker_probs\"])\n",
    "for representation in representations.keys() :\n",
    "    for index, row in combined_boards_df.iterrows():\n",
    "        board = row[\"boardwords\"]\n",
    "        boardname = row[\"boardnames\"]\n",
    "        wordpairlist = get_wordpair_list(boardname)\n",
    "        speaker_word_pairs = target_df[(target_df[\"boardnames\"] == row[\"boardnames\"]) & \n",
    "                                       (target_df[\"Experiment\"] == row[\"Experiment\"])][\"wordpair\"]\n",
    "        speaker_word_pairs = list(speaker_word_pairs)\n",
    "        speaker_df_new = pd.DataFrame({'wordpair': speaker_word_pairs})\n",
    "        params = rsa_optimal_params[representation]\n",
    "        speaker_model = pragmatic_speaker_np(boardname, params[0], params[1], representation)\n",
    "\n",
    "        ## this is created at the BOARD level\n",
    "        y = np.array([speaker_model[wordpairlist.index(wordpair)] for wordpair in speaker_word_pairs])\n",
    "        y_sorted = np.argsort(-y)\n",
    "\n",
    "        ## so y has 3 vectors of clue probabilities (the 3 pairs on this board)\n",
    "        ## now we need to go into expdata and score the probabilities for those specific clues\n",
    "        expdata_board = expdata[(expdata[\"Board\"] == row[\"Board\"]) & (expdata[\"Experiment\"] == row[\"Experiment\"])]\n",
    "        speaker_prob, speaker_rank = get_speaker_scores(expdata_board, speaker_word_pairs, y, y_sorted)\n",
    "        expdata_board.loc[:,\"representation\"] = representation\n",
    "        expdata_board.loc[:,\"prag_speaker_probs\"] = speaker_prob\n",
    "        expdata_board.loc[:,\"prag_speaker_rank\"] = speaker_rank\n",
    "        speakerprobs_df = pd.concat([speakerprobs_df, expdata_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESx0Uvm820s8"
   },
   "outputs": [],
   "source": [
    "speakerprobs_df.to_csv(\"../data/speaker_ranks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute top-n lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 17341,
     "status": "ok",
     "timestamp": 1620540149699,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 240
    },
    "id": "hxld3QX9s3zl",
    "outputId": "6c70c778-f751-4d65-8cfb-fdcdc521bf88"
   },
   "outputs": [],
   "source": [
    "## Creating a mainlist of boards\n",
    "speaker_df = pd.DataFrame(columns=['representation', 'wordpair','Board', 'prag_speaker_words'])\n",
    "\n",
    "for representation in representations.keys() :\n",
    "  for index, row in combined_boards_df.iterrows():\n",
    "    board_words = row[\"boardwords\"]\n",
    "    boardname = row[\"boardnames\"]\n",
    "    wordpairlist = get_wordpair_list(boardname)\n",
    "    params = rsa_optimal_params[representation]\n",
    "    speaker_model = pragmatic_speaker_np(boardname, params[0], params[1], representation)\n",
    "    ## get empirical speaker probs for this board\n",
    "    speaker_word_pairs = target_df[(target_df[\"boardnames\"] == row['boardnames']) & \n",
    "                                          (target_df[\"Experiment\"] == row['Experiment'])][\"wordpair\"]\n",
    "    speaker_df_new = pd.DataFrame({'wordpair': speaker_word_pairs})\n",
    "    speaker_df_new[\"Board\"] = boardname\n",
    "    speaker_df_new[\"representation\"] = representation\n",
    "    y = np.array([speaker_model[wordpairlist.index(wordpair)] for wordpair in speaker_word_pairs])\n",
    "\n",
    "    ## this will yield 3x10191 array [1-d array for each word-pair, 3 word-pairs per board]\n",
    "    ## from here we sort each row in descending order \n",
    "    y_sorted = np.argsort(-y) ## gives sorted indices\n",
    "    top20_indices = y_sorted[:,:20]\n",
    "\n",
    "    ## convert to words\n",
    "    w1 = [list(sample_df[\"Word\"])[i] for i in top20_indices[0]]\n",
    "    w2 = [list(sample_df[\"Word\"])[i] for i in top20_indices[1]]\n",
    "    w3 = [list(sample_df[\"Word\"])[i] for i in top20_indices[2]]\n",
    "    words = [w1, w2, w3]\n",
    "    speaker_df_new[\"prag_speaker_words\"] = words\n",
    "    speaker_df = pd.concat([speaker_df, speaker_df_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1R2bUvXLXd5"
   },
   "outputs": [],
   "source": [
    "speaker_df.to_csv(\"../data/speaker_top.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Wl5z7x0sSHr"
   },
   "source": [
    "## Listener predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84817,
     "status": "ok",
     "timestamp": 1620789421041,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "Pc1Ron6soZiC",
    "outputId": "517a4d89-3523-45ab-9dfb-09ae0c4f6a28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/roberthawkins/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/Users/roberthawkins/opt/miniconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "guesser_df = pd.DataFrame(columns=['Experiment','Board', \"Word1\", \"Word2\", \"Clue1\", \"clueCount\", \"wordpair\"])\n",
    "for representation in representations.keys() :\n",
    "    for index, row in combined_boards_df.iterrows():\n",
    "        guesser_df_board = pd.DataFrame(columns=['Experiment','Board', \"Word1\", \"Word2\", \"Clue1\", \"clueCount\", \"wordpair\"])\n",
    "        board = row[\"boardwords\"]\n",
    "        boardname = row['boardnames']\n",
    "        wordpairlist = get_wordpair_list(boardname)\n",
    "        # calculate the prag guesser for this specific wordpairlist (corresponding to ONE board)\n",
    "        params = rsa_optimal_params[representation]\n",
    "        x = literal_guesser_np(boardname, representation)\n",
    "        z = pragmatic_guesser_np(boardname, params[0], params[1], representation) \n",
    "\n",
    "        # then loop through the clues in expdata_board to get predictions\n",
    "        expdata_board = expdata[(expdata[\"Board\"] == row[\"Board\"]) & (expdata[\"Experiment\"] == row[\"Experiment\"])]\n",
    "        expdata_board.loc[:, \"representation\"] = representation\n",
    "\n",
    "        for index, row in expdata_board.iterrows():\n",
    "            clue1 = row[\"Clue1\"]\n",
    "            if clue1 in list(sample_df[\"Word\"]):\n",
    "                ## literal guesser uses \"x\", pragmatic guesser uses \"z\"\n",
    "                clue_index = list(sample_df[\"Word\"]).index(clue1)\n",
    "                literal_pred = wordpairlist[np.argmax(x[:,clue_index])]\n",
    "                pragmatic_pred = wordpairlist[np.argmax(z[:,clue_index])]\n",
    "            else:\n",
    "                literal_pred = \"NA\"\n",
    "                pragmatic_pred = \"NA\"\n",
    "\n",
    "            # we want to track likelihood for ALL responses (i.e. full listener distribution)\n",
    "            guesser_df_clue = pd.DataFrame({\n",
    "                'Clue1' : clue1, \n",
    "                'possible_wordpair' : wordpairlist,\n",
    "                'literal_likelihood' : x[:, clue_index],\n",
    "                'prag_likelihood' : z[:, clue_index],\n",
    "                'literal_top_prediction' : literal_pred,\n",
    "                'prag_top_prediction' : pragmatic_pred\n",
    "            })\n",
    "            guesser_df_board = pd.concat([guesser_df_board, pd.merge(expdata_board, guesser_df_clue)])\n",
    "        guesser_df = pd.concat([guesser_df, guesser_df_board])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0CU0nWdnpCGt"
   },
   "outputs": [],
   "source": [
    "guesser_df.to_csv(\"../data/guesser_scores.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyqIHCxY9rFT"
   },
   "source": [
    "## Get predictions for 'naive' context model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "SEzXZ7_r5I9B"
   },
   "outputs": [],
   "source": [
    "## define a func that computed similarities of clue to each word on the board\n",
    "## and then maximizes similarity to the words while minimizing similarity to other words\n",
    "def speaker_board_func(combs_df, context_board, alpha, beta, representation_model):\n",
    "    # grab subset of words in given board and their corresponding glove vectors\n",
    "    board_df = sample_df[sample_df['Word'].isin(context_board)]\n",
    "    board_word_indices = list(board_df.index)\n",
    "    board_words = board_df[\"Word\"]\n",
    "    board_vectors = representation_model[board_word_indices]\n",
    "\n",
    "    ## clue_sims is the similarity of ALL clues in full searchspace (size N) to EACH word on board (size 20)\n",
    "    clue_sims = (1-scipy.spatial.distance.cdist(board_vectors, representation_model, 'cosine') + 1 ) / 2\n",
    "    target_sample = target_df[target_df['Word1'].isin(board_df[\"Word\"]) & target_df['Word2'].isin(board_df[\"Word\"])]\n",
    "    w1_index = [list(board_df[\"Word\"]).index(row[\"Word1\"]) for index, row in target_sample.iterrows()]\n",
    "    w2_index = [list(board_df[\"Word\"]).index(row[\"Word2\"]) for index, row in target_sample.iterrows()]\n",
    "    clue_w1 = clue_sims[w1_index]\n",
    "    clue_w2 = clue_sims[w2_index]\n",
    "    clue_prod = np.multiply(clue_w1,clue_w2)\n",
    "\n",
    "    # deleting the two target words to compute average similarity to other words on the board\n",
    "    clue_sims_new = np.array([np.delete(clue_sims, [w1_index[i], w2_index[i]], axis=0) for i in range(len(w1_index))])\n",
    "    avg_sim = np.mean(clue_sims_new, axis=1)\n",
    "\n",
    "    ## FUNC = alpha(clue_w1*clue_w2) + (1-alpha)*(average of other board words)\n",
    "\n",
    "    func = np.subtract((alpha)*clue_prod, (1-alpha)*avg_sim)\n",
    "    return softmax(beta * func, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 265,
     "status": "ok",
     "timestamp": 1620751556240,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 300
    },
    "id": "CfYcPZiG13dd",
    "outputId": "11066401-87d3-4dc1-9297-02e13b11df92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(speaker_board_func(board_combos['e1_board10_words'], boards['e1_board10_words'], \n",
    "                                 0.7, 20, representations['glove']), axis = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NagfI7CbmqM"
   },
   "source": [
    "## Top Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 52847,
     "status": "ok",
     "timestamp": 1620679544331,
     "user": {
      "displayName": "Abhilasha Kumar",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3S_kn7pEo0LnvQDjGbOGbx0BmsP7fZY-0waKLnQ=s64",
      "userId": "00864468883555656933"
     },
     "user_tz": 300
    },
    "id": "I1uF2pvP-NF2",
    "outputId": "84dcfba8-3d7c-49d4-b609-7fc6e8296ad2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>boardnames</th>\n",
       "      <th>top10preds</th>\n",
       "      <th>alpha</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>void</td>\n",
       "      <td>couch</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>[David Bowie, United Kingdom, mussel, North Po...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giggle</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>[David Bowie, United Kingdom, mussel, North Po...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>[David Bowie, mussel, United Kingdom, North Po...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beginning</td>\n",
       "      <td>brake</td>\n",
       "      <td>e1_board2_words</td>\n",
       "      <td>[David Bowie, United Kingdom, mussel, North Po...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birds</td>\n",
       "      <td>aircraft</td>\n",
       "      <td>e1_board2_words</td>\n",
       "      <td>[David Bowie, mussel, United Kingdom, North Po...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>olive</td>\n",
       "      <td>real</td>\n",
       "      <td>e2_board9_words</td>\n",
       "      <td>[real, olive, lemon, Thanksgiving, purple, lof...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>candle</td>\n",
       "      <td>wick</td>\n",
       "      <td>e2_board9_words</td>\n",
       "      <td>[candle, wick, spark, wrench, cookie, hick, wa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>garage</td>\n",
       "      <td>bone</td>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>[bone, garage, fatigue, joints, stump, warehou...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feet</td>\n",
       "      <td>chapel</td>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>[cottage, sandals, tile, nuns, fabric, bathroo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chair</td>\n",
       "      <td>table</td>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>[chair, table, tables, stool, sofa, chamber, k...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BERT-sum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word1     Word2  ... alpha     Model\n",
       "0        void     couch  ...   0.0  BERT-sum\n",
       "1      giggle  abnormal  ...   0.0  BERT-sum\n",
       "2        exam   algebra  ...   0.0  BERT-sum\n",
       "0   beginning     brake  ...   0.0  BERT-sum\n",
       "1       birds  aircraft  ...   0.0  BERT-sum\n",
       "..        ...       ...  ...   ...       ...\n",
       "1       olive      real  ...   1.0  BERT-sum\n",
       "2      candle      wick  ...   1.0  BERT-sum\n",
       "0      garage      bone  ...   1.0  BERT-sum\n",
       "1        feet    chapel  ...   1.0  BERT-sum\n",
       "2       chair     table  ...   1.0  BERT-sum\n",
       "\n",
       "[660 rows x 6 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_board_df = pd.DataFrame(columns=['Word1', 'Word2', 'boardnames','top10preds', 'alpha', 'Model'])\n",
    "for representation in ['bert-sum', 'glove', 'swow']: \n",
    "    for alpha in np.arange(0,1.1, 0.1):\n",
    "        ## for a given alpha, compute the clue similarities \n",
    "        params = board_optimal_params[representation]\n",
    "        speaker_board_probs = {\n",
    "            board_name : speaker_board_func(board_combos[board_name], boards[board_name], alpha, params[0], representations[representation]) \n",
    "            for board_name in boards.keys()\n",
    "        }   \n",
    "        # we calculate the top5 speaker predictions for each word-pair based on highest value above\n",
    "        for board in speaker_board_probs.keys():\n",
    "            ## obtain top10 indices for each word-pair\n",
    "            idx = [(-speaker_board_probs[board][x]).argsort()[:10].tolist() for x in range(3)]\n",
    "            a = [list(sample_df[\"Word\"])[z] for y in idx for z in y]\n",
    "            top10preds = [list(arr) for arr in np.array_split(a, 3)]\n",
    "            speaker_df_new = pd.DataFrame({'boardnames': [board]*3})\n",
    "            speaker_df_new[\"Word1\"] = list(target_df[target_df['boardnames']== board][\"Word1\"])\n",
    "            speaker_df_new[\"Word2\"] = list(target_df[target_df['boardnames']== board][\"Word2\"])\n",
    "            speaker_df_new[\"alpha\"] = [alpha]*3\n",
    "            speaker_df_new[\"top10preds\"] = top10preds\n",
    "            speaker_df_new[\"Model\"] = representation\n",
    "            speaker_board_df = pd.concat([speaker_board_df, speaker_df_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGfbQB-b-VuL"
   },
   "outputs": [],
   "source": [
    "speaker_board_df.to_csv(\"../data/speaker_boardfunc_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlMlVQRIGK_j"
   },
   "source": [
    "## Obtain Clue Score for every possible Clue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1620793902197,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "XkB5vViPKXDo",
    "outputId": "28b7f69a-714c-4204-d1e9-132c26c0d262"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Board</th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>Clue1</th>\n",
       "      <th>clueCount</th>\n",
       "      <th>wordpair</th>\n",
       "      <th>boardwords</th>\n",
       "      <th>boardnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>calculus</td>\n",
       "      <td>1</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>[angry, adore, burglar, rumor, depth, anchor, ...</td>\n",
       "      <td>e1_board1_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>equation</td>\n",
       "      <td>1</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>[angry, adore, burglar, rumor, depth, anchor, ...</td>\n",
       "      <td>e1_board1_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>1</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>[angry, adore, burglar, rumor, depth, anchor, ...</td>\n",
       "      <td>e1_board1_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>math</td>\n",
       "      <td>22</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>[angry, adore, burglar, rumor, depth, anchor, ...</td>\n",
       "      <td>e1_board1_words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E1</td>\n",
       "      <td>TrialList1</td>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>school</td>\n",
       "      <td>2</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>[angry, adore, burglar, rumor, depth, anchor, ...</td>\n",
       "      <td>e1_board1_words</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Experiment  ...       boardnames\n",
       "0         E1  ...  e1_board1_words\n",
       "1         E1  ...  e1_board1_words\n",
       "2         E1  ...  e1_board1_words\n",
       "3         E1  ...  e1_board1_words\n",
       "4         E1  ...  e1_board1_words\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge expdata with combined_boards so we have the \"boardname\" correct\n",
    "expdata_new = pd.merge(expdata,combined_boards_df,on=['Board', 'Experiment'],how='left')\n",
    "expdata_new[\"wordpair\"] = expdata_new[\"Word1\"] + \"-\" + expdata_new[\"Word2\"]\n",
    "expdata_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1620793859201,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "FkLwu5mHMH-o",
    "outputId": "1fb839ac-f9b6-4c65-8421-a69947a4b112"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>boardnames</th>\n",
       "      <th>wordpair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>void</td>\n",
       "      <td>couch</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>void-couch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>giggle</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>giggle-abnormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>exam</td>\n",
       "      <td>algebra</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>exam-algebra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tea</td>\n",
       "      <td>bean</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board10_words</td>\n",
       "      <td>tea-bean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tourist</td>\n",
       "      <td>comedy</td>\n",
       "      <td>E1</td>\n",
       "      <td>e1_board10_words</td>\n",
       "      <td>tourist-comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word1     Word2 Experiment        boardnames         wordpair\n",
       "0     void     couch         E1   e1_board1_words       void-couch\n",
       "1   giggle  abnormal         E1   e1_board1_words  giggle-abnormal\n",
       "2     exam   algebra         E1   e1_board1_words     exam-algebra\n",
       "3      tea      bean         E1  e1_board10_words         tea-bean\n",
       "4  tourist    comedy         E1  e1_board10_words   tourist-comedy"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df[\"wordpair\"] = target_df[\"Word1\"] + \"-\" + target_df[\"Word2\"]\n",
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 611572,
     "status": "ok",
     "timestamp": 1620794540290,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "F5nrF5MCILaH",
    "outputId": "f6080071-848f-4869-b8cf-669e63eb69d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boardnames</th>\n",
       "      <th>wordpair</th>\n",
       "      <th>Clue1</th>\n",
       "      <th>clue_score</th>\n",
       "      <th>alpha</th>\n",
       "      <th>Model</th>\n",
       "      <th>clue_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>calculus</td>\n",
       "      <td>7.46495e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bert-sum</td>\n",
       "      <td>3812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>equation</td>\n",
       "      <td>5.92828e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bert-sum</td>\n",
       "      <td>4913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>3.59289e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bert-sum</td>\n",
       "      <td>8081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>math</td>\n",
       "      <td>6.25472e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bert-sum</td>\n",
       "      <td>4631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1_board1_words</td>\n",
       "      <td>exam-algebra</td>\n",
       "      <td>school</td>\n",
       "      <td>6.21898e-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bert-sum</td>\n",
       "      <td>4657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>garage-bone</td>\n",
       "      <td>storage</td>\n",
       "      <td>0.000495596</td>\n",
       "      <td>1.0</td>\n",
       "      <td>swow</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>garage-bone</td>\n",
       "      <td>structure</td>\n",
       "      <td>0.000288999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>swow</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>garage-bone</td>\n",
       "      <td>tool</td>\n",
       "      <td>0.00229715</td>\n",
       "      <td>1.0</td>\n",
       "      <td>swow</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>garage-bone</td>\n",
       "      <td>trash</td>\n",
       "      <td>0.00038321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>swow</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2_board10_words</td>\n",
       "      <td>garage-bone</td>\n",
       "      <td>underground</td>\n",
       "      <td>0.00021891</td>\n",
       "      <td>1.0</td>\n",
       "      <td>swow</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36168 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          boardnames      wordpair        Clue1  ... alpha     Model clue_rank\n",
       "0    e1_board1_words  exam-algebra     calculus  ...   0.0  bert-sum      3812\n",
       "0    e1_board1_words  exam-algebra     equation  ...   0.0  bert-sum      4913\n",
       "0    e1_board1_words  exam-algebra    knowledge  ...   0.0  bert-sum      8081\n",
       "0    e1_board1_words  exam-algebra         math  ...   0.0  bert-sum      4631\n",
       "0    e1_board1_words  exam-algebra       school  ...   0.0  bert-sum      4657\n",
       "..               ...           ...          ...  ...   ...       ...       ...\n",
       "0   e2_board10_words   garage-bone      storage  ...   1.0      swow       206\n",
       "0   e2_board10_words   garage-bone    structure  ...   1.0      swow       388\n",
       "0   e2_board10_words   garage-bone         tool  ...   1.0      swow        23\n",
       "0   e2_board10_words   garage-bone        trash  ...   1.0      swow       288\n",
       "0   e2_board10_words   garage-bone  underground  ...   1.0      swow       574\n",
       "\n",
       "[36168 rows x 7 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clue_board_df_main = pd.DataFrame(columns=['boardnames','wordpair', 'Clue1', 'clue_score', 'alpha', 'Model'])\n",
    "\n",
    "for representation in ['bert-sum', 'glove', 'swow']: \n",
    "  for alpha in np.arange(0,1.1, 0.1):\n",
    "    ## for a given alpha, compute the clue similarities \n",
    "    beta = board_optimal_params[representation][0]\n",
    "    speaker_board_probs = {\n",
    "        board_name : speaker_board_func(board_combos[board_name], boards[board_name], alpha, beta, representations[representation]) \n",
    "        for board_name in boards.keys()\n",
    "    }   \n",
    "    \n",
    "    for board in speaker_board_probs.keys():\n",
    "      \n",
    "      ## get the clues we need scores for from expdatanew\n",
    "      clue_main = expdata_new.loc[expdata_new['boardnames'] == board]\n",
    "      target_main = target_df.loc[target_df['boardnames'] == board]\n",
    "      \n",
    "      target_main.reset_index(inplace = True)\n",
    "      #print(target_main)\n",
    "\n",
    "      for index, row in clue_main.iterrows():\n",
    "        if row[\"Clue1\"] in list(sample_df[\"Word\"]):\n",
    "          #print(\"clue is:\", row[\"Clue1\"])\n",
    "          clue_index = list(sample_df[\"Word\"]).index(row[\"Clue1\"])\n",
    "          #print(\"clue_index:\",clue_index)\n",
    "          wordpair = row[\"wordpair\"]\n",
    "          ## need to figure out specific wordpair this clue corresponds to\n",
    "          wordpair_index = target_main.index[(target_main['wordpair'] == wordpair)].tolist()[0]\n",
    "          #print(\"wordpair_index:\",wordpair_index)\n",
    "          # get a sorted array of the clue scores\n",
    "          mainscores = speaker_board_probs[board][wordpair_index]\n",
    "          sorted_clue_probs = np.argsort(-mainscores).tolist()\n",
    "          #print(\"sorted_clue_probs_indices = \", sorted_clue_probs)\n",
    "          \n",
    "          # we next obtain the score for each clue for a specific wordpair\n",
    "          clue_similarity = speaker_board_probs[board][wordpair_index][clue_index]\n",
    "          # want to find index of this particular clue in the overall distribution\n",
    "          clue_rank = sorted_clue_probs.index(clue_index)\n",
    "          #print(\"clue_rank:\",clue_rank)\n",
    "        else:\n",
    "          clue_similarity = \"NA\"\n",
    "          clue_rank = \"NA\"\n",
    "        \n",
    "        clue_board_df = pd.DataFrame({'boardnames': [board]})\n",
    "        clue_board_df[\"wordpair\"] = wordpair\n",
    "        clue_board_df[\"Clue1\"] = row[\"Clue1\"]\n",
    "        clue_board_df[\"clue_score\"] = clue_similarity\n",
    "        clue_board_df[\"clue_rank\"] = clue_rank\n",
    "        clue_board_df[\"alpha\"] = alpha\n",
    "        clue_board_df[\"Model\"] = representation\n",
    "          \n",
    "        clue_board_df_main = pd.concat([clue_board_df_main, clue_board_df])\n",
    "\n",
    "clue_board_df_main                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDWHqi99Lm_8"
   },
   "outputs": [],
   "source": [
    "clue_board_df_main.to_csv(\"../data/speaker_boardfunc_df_ranks_softmax.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvfW-6IsLt-r"
   },
   "source": [
    "# Optimizing model params\n",
    "\n",
    "Our speaker models have two free parameters. In order to make a fair comparison across different representations, we want to find best version of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lMgt8GxNW-nr"
   },
   "outputs": [],
   "source": [
    "softplus = lambda x: np.log1p(np.exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize 'board' models (i.e. non-RSA way of incorporating context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "executionInfo": {
     "elapsed": 121930,
     "status": "error",
     "timestamp": 1620788884098,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "oO0LzmeoRH0y",
    "outputId": "ebf5f8b2-c4f6-4929-9d6f-8cbf0f69cd20"
   },
   "outputs": [],
   "source": [
    "representation = 'glove'\n",
    "def get_board_speaker_likelihood(params):\n",
    "    speaker_prob = []\n",
    "    beta = softplus(params[0])\n",
    "    alpha = expit(params[1])\n",
    "    representation_model = representations[representation]\n",
    "    for index, row in combined_boards_df.iterrows():\n",
    "        # grab subset of words in given board and their corresponding glove vectors\n",
    "        boardname = row[\"boardnames\"]\n",
    "        board_df = sample_df[sample_df['Word'].isin(boards[boardname])]\n",
    "        board_word_indices = list(board_df.index)\n",
    "        board_words = board_df[\"Word\"]\n",
    "        board_vectors = representation_model[board_word_indices]\n",
    "\n",
    "        ## clue_sims is the similarity of ALL clues in full searchspace (size N) to EACH word on board (size 20)\n",
    "        clue_sims = (1-scipy.spatial.distance.cdist(board_vectors, representation_model, 'cosine') + 1) / 2\n",
    "        target_sample = target_df[target_df['Word1'].isin(board_df[\"Word\"]) & target_df['Word2'].isin(board_df[\"Word\"])]\n",
    "        w1_index = [list(board_df[\"Word\"]).index(row[\"Word1\"]) for index, row in target_sample.iterrows()]\n",
    "        w2_index = [list(board_df[\"Word\"]).index(row[\"Word2\"]) for index, row in target_sample.iterrows()]\n",
    "        clue_w1 = clue_sims[w1_index]\n",
    "        clue_w2 = clue_sims[w2_index]\n",
    "        clue_prod = np.multiply(clue_w1, clue_w2)\n",
    "        clue_sims_new = np.array([np.delete(clue_sims, [w1_index[i], w2_index[i]], axis=0) for i in range(len(w1_index))])\n",
    "        avg_sim = np.mean(clue_sims_new, axis=1)\n",
    "        func = np.subtract((alpha)*clue_prod, (1-alpha)*avg_sim)\n",
    "        y = softmax(beta * func, axis=1)\n",
    "        expdata_board = expdata[(expdata[\"Board\"] == row[\"Board\"]) & (expdata[\"Experiment\"] == row[\"Experiment\"])]\n",
    "        speaker_word_pairs = list(target_sample['wordpair'])\n",
    "        for index, row in expdata_board.iterrows():\n",
    "            wordpair = str(row[\"wordpair\"]).replace(\" \", \"\")\n",
    "            wordpair_index = speaker_word_pairs.index(wordpair)\n",
    "            clue1 = row[\"Clue1\"]\n",
    "            if clue1 in list(sample_df[\"Word\"]):\n",
    "                # find index of clue\n",
    "                clue_index = list(sample_df[\"Word\"]).index(clue1)\n",
    "                clue_probs = y[wordpair_index, clue_index]\n",
    "                speaker_prob.append(row['clueCount'] * np.log(clue_probs))\n",
    "    print(beta, alpha, '(', params[1], ')', ':', np.sum(speaker_prob))\n",
    "    return -np.sum(speaker_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these lines gives a good 'initialization' for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.optimize.minimize(get_board_speaker_likelihood, [24, 3.349]) # optimize for 'swow'\n",
    "#scipy.optimize.minimize(get_board_speaker_likelihood, [20.6, 3.349]) # optimize for 'glove'\n",
    "scipy.optimize.minimize(get_board_speaker_likelihood, [1, 5]) # optimize for 'bert-sum'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize RSA speaker models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 902
    },
    "executionInfo": {
     "elapsed": 276789,
     "status": "error",
     "timestamp": 1620788608520,
     "user": {
      "displayName": "Robert Hawkins",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiqGTtXNDJINdLVVy9iBBFVLUYe9UyQWhEaBwPLqw=s64",
      "userId": "13623832260192960306"
     },
     "user_tz": 420
    },
    "id": "PRtJFUjBzbJe",
    "outputId": "8c27cd24-ee09-42bc-f98e-a7b9550b85ae"
   },
   "outputs": [],
   "source": [
    "representation = 'swow'\n",
    "\n",
    "def get_rsa_speaker_likelihood(params) :\n",
    "  # params is a list\n",
    "  speaker_prob = []\n",
    "  beta = softplus(params[0])\n",
    "  costweight = expit(params[1])\n",
    "  for index, row in combined_boards_df.iterrows():\n",
    "    board = row[\"boardwords\"]\n",
    "    boardname = row[\"boardnames\"]\n",
    "    wordpairlist = get_wordpair_list(boardname)\n",
    "    speaker_word_pairs = target_df[(target_df[\"boardnames\"] == row[\"boardnames\"]) & \n",
    "                                   (target_df[\"Experiment\"] == row[\"Experiment\"])][\"wordpair\"]\n",
    "    speaker_model = pragmatic_speaker_np(boardname, beta, costweight, representation)\n",
    "    y = np.array([speaker_model[wordpairlist.index(wordpair)] for wordpair in speaker_word_pairs])\n",
    "    expdata_board = expdata[(expdata[\"Board\"] == row[\"Board\"]) & (expdata[\"Experiment\"] == row[\"Experiment\"])]\n",
    "    speaker_word_pairs = list(speaker_word_pairs)\n",
    "    for index, row in expdata_board.iterrows():\n",
    "      wordpair = str(row[\"wordpair\"]).replace(\" \", \"\")\n",
    "      wordpair_index = speaker_word_pairs.index(wordpair)\n",
    "      clue1 = row[\"Clue1\"]\n",
    "      if clue1 in list(sample_df[\"Word\"]):\n",
    "        clue_index = list(sample_df[\"Word\"]).index(clue1)\n",
    "        clue_probs = y[wordpair_index, clue_index]\n",
    "        speaker_prob.append(row['clueCount'] * np.log(clue_probs))\n",
    "  print(beta, costweight, '(', params[1], ')', ':', np.sum(speaker_prob))\n",
    "  return -np.sum(speaker_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scipy.optimize.minimize(get_board_speaker_likelihood, [24, 3.349]) # optimize for 'swow'\n",
    "#scipy.optimize.minimize(get_board_speaker_likelihood, [20.6, 3.349]) # optimize for 'glove'\n",
    "scipy.optimize.minimize(get_rsa_speaker_likelihood, [25.399, -3.219]) # optimize for 'swow'"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
