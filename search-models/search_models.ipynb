{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhilasha-kumar/Connector/blob/master/search-models/search_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH3K3UX0r_uM"
      },
      "source": [
        "# Importing packages and mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abhilasha-kumar/Connector.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU7It8y3eUZ4",
        "outputId": "bfb8a391-88ec-4f06-fa91-c62e87523a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'search-models'...\n",
            "remote: Not Found\n",
            "fatal: repository 'https://github.com/abhilasha-kumar/Connector/search-models.git/' not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLHTgCLD-5VS"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import operator\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "import heapq\n",
        "import pandas as pd\n",
        "import scipy.spatial.distance\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "from sklearn.preprocessing import MinMaxScaler, normalize\n",
        "from numpy.linalg import matrix_power\n",
        "from scipy import stats\n",
        "from sklearn import preprocessing\n",
        "from numpy.random import choice\n",
        "import json\n",
        "import heapq\n",
        "import json\n",
        "import itertools\n",
        "import sys\n",
        "import scipy.spatial.distance\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_BINlf1Pwzc",
        "outputId": "2c4efd7c-fe67-43cb-b474-68d74202b187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54ZMyOWfsEGS"
      },
      "source": [
        "# Importing embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxoEmRAHPuDn",
        "outputId": "ff1fb363-e98a-4642-ecd7-f325d7ce1ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embeddings are shaped: (12218, 300)\n",
            "vocab is 12218 words\n"
          ]
        }
      ],
      "source": [
        "# import glove embeddings\n",
        "representations = {}\n",
        "parentfolder = \"/content/drive/My Drive/Connector-CogSci2021/Descriptive analyses and model predictions/\"\n",
        "representations['glove'] = pd.read_csv(parentfolder +\"glove_embeddings.csv\").transpose().values\n",
        "vocab = pd.read_csv(parentfolder +\"vocab_final.csv\")\n",
        "print(f\"embeddings are shaped:\", representations['glove'].shape)\n",
        "print(f\"vocab is {len(vocab)} words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urqF5SZjsF7h"
      },
      "source": [
        "# Defining search & RSA functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import search functions\n",
        "%run -i \"/content/drive/My Drive/search-models/create_similarity_matrix.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/create_graph.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/random_walk.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/union_intersection.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/predication_vector.py\"\n",
        "\n",
        "# import RSA functions\n",
        "%run -i \"/content/drive/My Drive/search-models/compute_board_combos.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/get_wordpair_list.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/create_board_matrix.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/literal_guesser.py\"\n",
        "%run -i \"/content/drive/My Drive/search-models/pragmatic_speaker.py\""
      ],
      "metadata": {
        "id": "JmGNpS85zn01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parentfolder = \"/content/drive/My Drive/Connector-CogSci2021/Descriptive analyses and model predictions/\"\n",
        "with open(parentfolder + 'boards.json', 'r') as json_file:\n",
        "    boards = json.load(json_file)\n",
        "board_combos = {board_name : compute_board_combos(board_name,boards) for board_name in boards.keys()}"
      ],
      "metadata": {
        "id": "NA8E0i-w4RGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing similarity matrix & Graph"
      ],
      "metadata": {
        "id": "iHSQU9ln8LBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.4\n",
        "sim_matrix_glove = create_similarity_matrix(representations['glove'])\n",
        "Graph = create_graph(sim_matrix_glove, threshold)"
      ],
      "metadata": {
        "id": "LTu8Gi5uzzrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c46cGdcHMM2q"
      },
      "source": [
        "# Running an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4voFxHxOb22",
        "outputId": "a41de519-2c71-4b54-b85a-7a407cc25ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "314 items in union: ['mathematics', 'math', 'level', 'intend', 'chance', 'better', 'imply', 'apply', 'school', 'basic', 'learning', 'enable', 'choose', 'praise', 'processor', 'proceed', 'polygon', 'problem', 'probability', 'prediction', 'prior', 'precisely', 'prestigious', 'preschool', 'produce', 'preparation', 'primary', 'pronunciation', 'product', 'range', 'register', 'regard', 'refute', 'refuse', 'recognize', 'ratio', 'rather', 'quotient', 'professor', 'quantum', 'psychology', 'psychologist', 'psychiatric', 'proton', 'proposal', 'physics', 'plead', 'pack', 'perfect', 'particular', 'mostly', 'monastery', 'momentum', 'might', 'medicine', 'maximum', 'matrix', 'mathematical', 'market', 'manufacturer', 'mandatory', 'management', 'loop', 'logical', 'logic', 'multiplication', 'multiply', 'nature', 'occupy', 'particle', 'parameter', 'outdoor', 'orphanage', 'operate', 'offer', 'obligatory', 'need', 'objective', 'nursery', 'notion', 'none', 'never', 'neurology', 'regret', 'abstract', 'regulation', 'third', 'triangle', 'transfer', 'transaction', 'today', 'ticket', 'throw', 'though', 'think', 'teaching', 'theory', 'theorize', 'theorem', 'test', 'tend', 'technology', 'tech', 'trigonometry', 'trivial', 'try', 'tuition', 'wrong', 'without', 'widget', 'way', 'wages', 'vote', 'vector', 'varied', 'use', 'unpredictable', 'unlike', 'university', 'unemployed', 'unconscious', 'turn', 'team', 'teacher', 'relevant', 'script', 'senior', 'semester', 'selling', 'sell', 'select', 'secretary', 'secondary', 'science', 'tangent', 'safety', 'rotation', 'ridiculous', 'resource', 'resident', 'requirement', 'linear', 'sense', 'serious', 'significance', 'simple', 'system', 'symmetry', 'switch', 'survey', 'support', 'subtraction', 'subject', 'student', 'stipend', 'stay', 'state', 'spin', 'speech', 'specific', 'span', 'require', 'least', 'length', 'decompose', 'course', 'correct', 'conversation', 'confront', 'conclusion', 'compulsory', 'comprehensive', 'complicated', 'completion', 'community', 'communication', 'college', 'collection', 'clique', 'classroom', 'decide', 'decomposition', 'choice', 'define', 'dislike', 'discuss', 'discus', 'diploma', 'dining room', 'dimension', 'difficult', 'diagonal', 'develop', 'desktop', 'describe', 'derivative', 'depth', 'density', 'dense', 'citizenship', 'charge', 'document', 'arithmetic', 'approximate', 'anatomy', 'analysis', 'analogy', 'amongst', 'also', 'alphabet', 'algebra', 'aim', 'adopt', 'admit', 'admission', 'additionally', 'accuse', 'accomplishment', 'approximation', 'art', 'certify', 'artwork', 'certificate', 'capability', 'calculus', 'calculation', 'calculate', 'bundle', 'bring', 'book', 'behind', 'bathtub', 'bathroom', 'attempt', 'athlete', 'assistant', 'assessment', 'distribute', 'draw', 'lend', 'inhabitant', 'infinite', 'industry', 'indeed', 'impulsive', 'impossible', 'illustrate', 'idea', 'horrifying', 'hire', 'highest', 'hence', 'guideline', 'great', 'graph', 'grant', 'inform', 'inner', 'graduation', 'input', 'lecturer', 'academic', 'leaf', 'later', 'largely', 'large', 'jury', 'journalism', 'job', 'inverse', 'invent', 'integer', 'instance', 'inspection', 'inquiry', 'grammar', 'graduate', 'ease', 'experience', 'exclusive', 'exclude', 'exception', 'excel', 'exams', 'examination', 'exam', 'everything', 'ever', 'Europe', 'equipment', 'equation', 'entrance', 'entirely', 'education', 'expensive', 'explain', 'grade', 'fact', 'get', 'geometry', 'geometric', 'gather', 'furthermore', 'function', 'Freud', 'frequently', 'forget', 'following', 'finite', 'finding', 'fee', 'favorite', 'familiar', 'zero']\n",
            "13 items in intersection: ['mathematics', 'math', 'intend', 'level', 'apply', 'basic', 'better', 'chance', 'choose', 'enable', 'imply', 'learning', 'school']\n",
            "for wordpair exam-algebra and clue mathematics\n",
            "ON FULL VOCAB\n",
            "literal guesser prediction is: exam-algebra\n",
            "top 5 prag speaker predictions are: ['algebra', 'exam', 'mathematics', 'exams', 'calculus']\n",
            "ON CANDIDATES\n",
            "GUESSER candidate UNION prediction is: exam-algebra\n",
            "GUESSER candidate INTERSECTION prediction is: exam-algebra\n",
            "top 5 SPEAKER candidate UNION are: ['algebra', 'exam', 'mathematics', 'exams', 'calculus']\n",
            "top 5 prag SPEAKER candidate INTERSECTION are: ['mathematics', 'math', 'apply', 'school', 'basic']\n",
            "SIMPLE UNION/INTERSECTION\n",
            "considering top 5 nodes visited by union and intersection...\n",
            "highly visited nodes in the union: ['mathematics', 'math', 'level', 'intend', 'chance']\n",
            "highly visited nodes in the intersection: ['mathematics', 'math', 'intend', 'level', 'apply']\n"
          ]
        }
      ],
      "source": [
        "target = 'exam-algebra'\n",
        "w1, w2 = target.split(sep = \"-\")\n",
        "n_steps = 5\n",
        "n_walks = 50\n",
        "\n",
        "# computing union and intersection of independent walks\n",
        "u, i = union_intersection(w1,w2, n_steps, n_walks, vocab)\n",
        "\n",
        "union_candidates = list(u.vocab_word)\n",
        "int_candidates = list(i.vocab_word)\n",
        "\n",
        "print(f\"{len(u)} items in union: {union_candidates}\")\n",
        "print(f\"{len(i)} items in intersection: {int_candidates}\")\n",
        "\n",
        "clue = 'mathematics'\n",
        "n = 5\n",
        "wordpairlist = get_wordpair_list(board_combos, 'e1_board1_words')\n",
        "target_index = wordpairlist.index(target)\n",
        "clue_index = list(vocab[\"vocab_word\"]).index(clue)\n",
        "\n",
        "print(f\"for wordpair {target} and clue {clue}\")\n",
        "\n",
        "\n",
        "## compute predictions on FULL vocab\n",
        "\n",
        "print(f\"ON FULL VOCAB\")\n",
        "\n",
        "a = literal_guesser('e1_board1_words', 'glove', list(vocab.vocab_word) , vocab, boards)[:,clue_index]\n",
        "y = pragmatic_speaker('e1_board1_words', 18.858, 0.004, 'glove',list(vocab.vocab_word) , vocab, boards)\n",
        "\n",
        "print(\"literal guesser prediction is:\", wordpairlist[np.argmax(a)])\n",
        "top = y[target_index,:].argsort()[-n:][::-1].tolist()\n",
        "top_words = [list(vocab[\"vocab_word\"])[x] for x in top]\n",
        "print(f\"top {n} prag speaker predictions are:\", top_words)\n",
        "\n",
        "print(f\"ON CANDIDATES\")\n",
        "\n",
        "b_union = literal_guesser('e1_board1_words', 'glove', union_candidates, vocab, boards)[:, union_candidates.index(clue)]\n",
        "c_union = pragmatic_speaker('e1_board1_words', 18.858, 0.004, 'glove', union_candidates, vocab, boards)\n",
        "\n",
        "b_int = literal_guesser('e1_board1_words', 'glove', int_candidates, vocab, boards)[:, int_candidates.index(clue)]\n",
        "c_int = pragmatic_speaker('e1_board1_words', 18.858, 0.004, 'glove', int_candidates, vocab, boards)\n",
        "\n",
        "print(\"GUESSER candidate UNION prediction is:\", wordpairlist[np.argmax(b_union)])\n",
        "print(\"GUESSER candidate INTERSECTION prediction is:\", wordpairlist[np.argmax(b_int)])\n",
        "\n",
        "top = c_union[target_index,:].argsort()[-n:][::-1].tolist()\n",
        "top_words = [list(u.vocab_word)[x] for x in top]\n",
        "print(f\"top {n} SPEAKER candidate UNION are:\", top_words)\n",
        "\n",
        "top = c_int[target_index,:].argsort()[-n:][::-1].tolist()\n",
        "top_words = [list(i.vocab_word)[x] for x in top]\n",
        "print(f\"top {n} prag SPEAKER candidate INTERSECTION are:\", top_words)\n",
        "\n",
        "print(f\"SIMPLE UNION/INTERSECTION\")\n",
        "print(f\"considering top {n} nodes visited by union and intersection...\")\n",
        "print(f\"highly visited nodes in the union: {union_candidates[:n]}\")\n",
        "print(f\"highly visited nodes in the intersection: {int_candidates[:n]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtuHKP7ItXDy"
      },
      "source": [
        "# Running through full dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlh_haE7tazm"
      },
      "outputs": [],
      "source": [
        "expdata = pd.read_csv(parentfolder + \"final_board_clues_all.csv\", encoding= 'unicode_escape')\n",
        "\n",
        "\n",
        "allcombinations_df = pd.DataFrame(columns=['Board', 'Word1','Word2', 'wordpair'])\n",
        "\n",
        "\n",
        "for board in board_combos:\n",
        "    newdf = board_combos[board]\n",
        "    newdf.insert(loc=0, column='Board', value=board)\n",
        "    allcombinations_df = pd.concat([allcombinations_df, newdf])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cqRx40xQuKS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "search-models.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNn4d8FgIVE1jcCb9rLqapr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}